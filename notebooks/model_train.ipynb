{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Best Model Using Uber Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor,GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "# model\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "#model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "# metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import optuna\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading, Cleaning, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1          7.7 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2         12.9 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3          5.3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4         16.0 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/uber.csv\", parse_dates=['pickup_datetime'])\n",
    "df.drop(['Unnamed: 0','key'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference: The Dataset consists of 7 features & 200000 samples.\n"
     ]
    }
   ],
   "source": [
    "print(f'Inference: The Dataset consists of {df.shape[1]} features & {df.shape[0]} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Total Null Values  Percentage\n",
      "fare_amount                        0         0.0\n",
      "pickup_datetime                    0         0.0\n",
      "pickup_longitude                   0         0.0\n",
      "pickup_latitude                    0         0.0\n",
      "passenger_count                    0         0.0\n",
      "dropoff_longitude                  1         0.0\n",
      "dropoff_latitude                   1         0.0\n"
     ]
    }
   ],
   "source": [
    "nullValues = pd.DataFrame(df.isnull().sum().sort_values(), columns=['Total Null Values'])\n",
    "nullValues['Percentage'] = round(nullValues['Total Null Values']/df.shape[0],3)*100\n",
    "print(nullValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount          0\n",
       "pickup_datetime      0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "passenger_count      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()# after clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()#checking duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 7)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delete = df[(df['pickup_latitude']>180) | (df['pickup_latitude']<-180)|\n",
    "                    (df['dropoff_latitude']>180) | (df['dropoff_latitude']< -180)|\n",
    "                    (df['pickup_longitude']>90) | (df['pickup_longitude']<-90) |\n",
    "                    (df['dropoff_longitude']>90) | (df['dropoff_longitude']<-90)]\n",
    "df_delete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  4949,  32549,  40908,  48506,  56617,  61793,  75851,  91422, 103745,\n",
       "       139447, 144253, 161652, 199936],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_delete = df_delete.index\n",
    "index_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :199999,after :199986\n"
     ]
    }
   ],
   "source": [
    "before = df.shape\n",
    "df.drop(index_to_delete,inplace=True)\n",
    "print(f'before :{before[0]},after :{df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.pickup_datetime.dt.year\n",
    "df['month'] = df.pickup_datetime.dt.month\n",
    "df['weekday'] = df.pickup_datetime.dt.weekday\n",
    "df['hour'] = df.pickup_datetime.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Monthly_Quarter'] = df.month.map({1:'Q1',2:'Q1',3:'Q1',4:'Q2',5:'Q2',6:'Q2',7:'Q3',\n",
    "                                      8:'Q3',9:'Q3',10:'Q4',11:'Q4',12:'Q4'})\n",
    "\n",
    "df['Hourly_Segments'] = df.hour.map({0:'H1',1:'H1',2:'H1',3:'H1',4:'H2',5:'H2',6:'H2',7:'H2',8:'H3',\n",
    "                                     9:'H3',10:'H3',11:'H3',12:'H4',13:'H4',14:'H4',15:'H4',16:'H5',\n",
    "                                     17:'H5',18:'H5',19:'H5',20:'H6',21:'H6',22:'H6',23:'H6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>Monthly_Quarter</th>\n",
       "      <th>Hourly_Segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>Q2</td>\n",
       "      <td>H5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Q3</td>\n",
       "      <td>H6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Q3</td>\n",
       "      <td>H6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Q2</td>\n",
       "      <td>H3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>Q3</td>\n",
       "      <td>H5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          7.5 2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1          7.7 2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2         12.9 2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3          5.3 2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4         16.0 2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  year  month  weekday  \\\n",
       "0         -73.999512         40.723217                1  2015      5        3   \n",
       "1         -73.994710         40.750325                1  2009      7        4   \n",
       "2         -73.962565         40.772647                1  2009      8        0   \n",
       "3         -73.965316         40.803349                3  2009      6        4   \n",
       "4         -73.973082         40.761247                5  2014      8        3   \n",
       "\n",
       "   hour Monthly_Quarter Hourly_Segments  \n",
       "0    19              Q2              H5  \n",
       "1    20              Q3              H6  \n",
       "2    21              Q3              H6  \n",
       "3     8              Q2              H3  \n",
       "4    17              Q3              H5  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['pickup_datetime','month', 'hour',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, asin\n",
    "\n",
    "def distance_transform(longitude1, latitude1, longitude2, latitude2):\n",
    "    travel_dist = []\n",
    "    \n",
    "    for pos in range(len(longitude1)):\n",
    "        long1,lati1,long2,lati2 = map(radians,[longitude1[pos],latitude1[pos],longitude2[pos],latitude2[pos]])\n",
    "        dist_long = long2 - long1\n",
    "        dist_lati = lati2 - lati1\n",
    "        a = sin(dist_lati/2)**2 + cos(lati1) * cos(lati2) * sin(dist_long/2)**2\n",
    "        c = 2 * asin(sqrt(a))*6371\n",
    "        travel_dist.append(c)\n",
    "       \n",
    "    return travel_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_traveled']=distance_transform(df['pickup_longitude'].to_numpy(),\n",
    "                                  df['pickup_latitude'].to_numpy(),\n",
    "                                  df['dropoff_longitude'].to_numpy(),\n",
    "                                  df['dropoff_latitude'].to_numpy())\n",
    "## This Distance is in kilometers\n",
    "df['distance_traveled'] = df['distance_traveled'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 11)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['fare_amount']<= 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 11)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fare_delete = df[df['fare_amount']<=0]\n",
    "df_fare_delete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items removed : 22\n"
     ]
    }
   ],
   "source": [
    "old_shape = df.shape\n",
    "index_to_delete_fare = df_fare_delete.index\n",
    "df.drop(index_to_delete_fare,inplace=True)\n",
    "print(f\"Number of items removed : {old_shape[0] - df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "1      138404\n",
       "2       29423\n",
       "5       14004\n",
       "3        8878\n",
       "4        4275\n",
       "6        4271\n",
       "0         708\n",
       "208         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop 1\n"
     ]
    }
   ],
   "source": [
    "old_shape = df.shape\n",
    "index_to_delete_passenger = df[df['passenger_count']==df['passenger_count'].max()].index\n",
    "df.drop(index_to_delete_passenger,inplace=True)\n",
    "print(f\"After drop {old_shape[0] - df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "1    138404\n",
       "2     29423\n",
       "5     14004\n",
       "3      8878\n",
       "4      4275\n",
       "6      4271\n",
       "0       708\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the large passenger count is removed 208 column\n",
    "df['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will replace 0 with 1 count\n",
    "df['passenger_count']=np.where(df['passenger_count']==0,1,df['passenger_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "1    139112\n",
       "2     29423\n",
       "5     14004\n",
       "3      8878\n",
       "4      4275\n",
       "6      4271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>distance_traveled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "      <td>194247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.349822</td>\n",
       "      <td>-73.826480</td>\n",
       "      <td>40.646902</td>\n",
       "      <td>-73.837556</td>\n",
       "      <td>40.651579</td>\n",
       "      <td>1.687413</td>\n",
       "      <td>2011.747420</td>\n",
       "      <td>3.048577</td>\n",
       "      <td>21.060440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.722955</td>\n",
       "      <td>3.660507</td>\n",
       "      <td>2.931640</td>\n",
       "      <td>3.536295</td>\n",
       "      <td>2.900095</td>\n",
       "      <td>1.303961</td>\n",
       "      <td>1.859941</td>\n",
       "      <td>1.946791</td>\n",
       "      <td>384.091421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>-89.933333</td>\n",
       "      <td>-74.015515</td>\n",
       "      <td>-75.458979</td>\n",
       "      <td>-74.015750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>-73.992269</td>\n",
       "      <td>40.736348</td>\n",
       "      <td>-73.991589</td>\n",
       "      <td>40.735220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.982116</td>\n",
       "      <td>40.753253</td>\n",
       "      <td>-73.980539</td>\n",
       "      <td>40.753708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>-73.968400</td>\n",
       "      <td>40.767508</td>\n",
       "      <td>-73.965423</td>\n",
       "      <td>40.768314</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>40.808425</td>\n",
       "      <td>48.018760</td>\n",
       "      <td>40.831932</td>\n",
       "      <td>45.031598</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8782.899000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count  194247.000000     194247.000000    194247.000000      194247.000000   \n",
       "mean       11.349822        -73.826480        40.646902         -73.837556   \n",
       "std         9.722955          3.660507         2.931640           3.536295   \n",
       "min         0.010000        -89.933333       -74.015515         -75.458979   \n",
       "25%         6.000000        -73.992269        40.736348         -73.991589   \n",
       "50%         8.500000        -73.982116        40.753253         -73.980539   \n",
       "75%        12.500000        -73.968400        40.767508         -73.965423   \n",
       "max       499.000000         40.808425        48.018760          40.831932   \n",
       "\n",
       "       dropoff_latitude  passenger_count           year        weekday  \\\n",
       "count     194247.000000    194247.000000  194247.000000  194247.000000   \n",
       "mean          40.651579         1.687413    2011.747420       3.048577   \n",
       "std            2.900095         1.303961       1.859941       1.946791   \n",
       "min          -74.015750         1.000000    2009.000000       0.000000   \n",
       "25%           40.735220         1.000000    2010.000000       1.000000   \n",
       "50%           40.753708         1.000000    2012.000000       3.000000   \n",
       "75%           40.768314         2.000000    2013.000000       5.000000   \n",
       "max           45.031598         6.000000    2015.000000       6.000000   \n",
       "\n",
       "       distance_traveled  \n",
       "count      194247.000000  \n",
       "mean           21.060440  \n",
       "std           384.091421  \n",
       "min             0.001000  \n",
       "25%             1.283000  \n",
       "50%             2.185000  \n",
       "75%             3.961000  \n",
       "max          8782.899000  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing zero distance travel\n",
    "index_to_delete_distance = df[df['distance_traveled'] == 0].index\n",
    "df.drop(index_to_delete_distance,inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.distance_traveled < 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :194247,after :193166\n"
     ]
    }
   ],
   "source": [
    "# removing 100m distance traveled\n",
    "before = df.shape\n",
    "df.drop(df[df.distance_traveled < 0.1].index, inplace=True)\n",
    "print(f\"before :{before[0]},after :{df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Monthly_Quarter</th>\n",
       "      <th>Hourly_Segments</th>\n",
       "      <th>distance_traveled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>15.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.979805</td>\n",
       "      <td>40.786030</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>H5</td>\n",
       "      <td>8666.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>52.00</td>\n",
       "      <td>-73.781095</td>\n",
       "      <td>40.645015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>Q1</td>\n",
       "      <td>H6</td>\n",
       "      <td>8647.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>2.50</td>\n",
       "      <td>-74.001849</td>\n",
       "      <td>40.715156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>Q2</td>\n",
       "      <td>H4</td>\n",
       "      <td>8666.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>10.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.953210</td>\n",
       "      <td>40.803528</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>Q3</td>\n",
       "      <td>H6</td>\n",
       "      <td>8664.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>15.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.843777</td>\n",
       "      <td>40.739255</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>H1</td>\n",
       "      <td>8654.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196967</th>\n",
       "      <td>57.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.789045</td>\n",
       "      <td>40.655135</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>H3</td>\n",
       "      <td>8647.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197468</th>\n",
       "      <td>6.90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.980827</td>\n",
       "      <td>40.747133</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>H5</td>\n",
       "      <td>8665.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197863</th>\n",
       "      <td>7.00</td>\n",
       "      <td>-73.962190</td>\n",
       "      <td>40.759158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>Q4</td>\n",
       "      <td>H6</td>\n",
       "      <td>8664.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198567</th>\n",
       "      <td>23.50</td>\n",
       "      <td>-73.968115</td>\n",
       "      <td>40.801455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>Q4</td>\n",
       "      <td>H1</td>\n",
       "      <td>8665.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198665</th>\n",
       "      <td>20.10</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>40.729775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>H6</td>\n",
       "      <td>4528.960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "346           15.50          0.000000         0.000000         -73.979805   \n",
       "1067          52.00        -73.781095        40.645015           0.000000   \n",
       "1526           2.50        -74.001849        40.715156           0.000000   \n",
       "2547          10.10          0.000000         0.000000         -73.953210   \n",
       "3045          15.00          0.000000         0.000000         -73.843777   \n",
       "...             ...               ...              ...                ...   \n",
       "196967        57.33          0.000000         0.000000         -73.789045   \n",
       "197468         6.90          0.000000         0.000000         -73.980827   \n",
       "197863         7.00        -73.962190        40.759158           0.000000   \n",
       "198567        23.50        -73.968115        40.801455           0.000000   \n",
       "198665        20.10         -0.116667        40.729775           0.000000   \n",
       "\n",
       "        dropoff_latitude  passenger_count  year  weekday Monthly_Quarter  \\\n",
       "346            40.786030                1  2015        3              Q1   \n",
       "1067            0.000000                1  2014        6              Q1   \n",
       "1526            0.000000                3  2014        0              Q2   \n",
       "2547           40.803528                2  2011        1              Q3   \n",
       "3045           40.739255                1  2013        1              Q1   \n",
       "...                  ...              ...   ...      ...             ...   \n",
       "196967         40.655135                2  2014        2              Q3   \n",
       "197468         40.747133                5  2011        2              Q1   \n",
       "197863          0.000000                1  2014        1              Q4   \n",
       "198567          0.000000                2  2013        0              Q4   \n",
       "198665          0.000000                5  2012        1              Q2   \n",
       "\n",
       "       Hourly_Segments  distance_traveled  \n",
       "346                 H5           8666.398  \n",
       "1067                H6           8647.036  \n",
       "1526                H4           8666.772  \n",
       "2547                H6           8664.557  \n",
       "3045                H1           8654.177  \n",
       "...                ...                ...  \n",
       "196967              H3           8647.904  \n",
       "197468              H5           8665.686  \n",
       "197863              H6           8664.389  \n",
       "198567              H1           8665.747  \n",
       "198665              H6           4528.960  \n",
       "\n",
       "[379 rows x 11 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delete_lat_long = df[(df['pickup_longitude']==0) | (df['pickup_latitude']==0) | (df['dropoff_longitude']==0) | (df['dropoff_latitude']==0) ]\n",
    "df_delete_lat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop 379\n"
     ]
    }
   ],
   "source": [
    "old_shape = df.shape\n",
    "index_to_delete_lat_long = df[(df['pickup_longitude']==0) | (df['pickup_latitude']==0) | (df['dropoff_longitude']==0) | (df['dropoff_latitude']==0) ].index\n",
    "df.drop(index_to_delete_lat_long,inplace=True)\n",
    "print(f\"After drop {old_shape[0] - df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour Segments Decoded Categories: ['H5' 'H6' 'H6' ... 'H1' 'H4' 'H2']\n",
      "Decoded Categories: ['Q2' 'Q3' 'Q3' ... 'Q2' 'Q2' 'Q2']\n"
     ]
    }
   ],
   "source": [
    "Hour_encoder = LabelEncoder()\n",
    "Month_encoder = LabelEncoder()\n",
    "\n",
    "df.Monthly_Quarter = Month_encoder.fit_transform(df.Monthly_Quarter)\n",
    "df.Hourly_Segments = Hour_encoder.fit_transform(df.Hourly_Segments)\n",
    "\n",
    "Hour_Segments_decoded = Hour_encoder.inverse_transform(df.Hourly_Segments)\n",
    "print(\"Hour Segments Decoded Categories:\", Hour_Segments_decoded)\n",
    "\n",
    "Month_Segments_decoded = Month_encoder.inverse_transform(df.Monthly_Quarter)\n",
    "print(\"Decoded Categories:\", Month_Segments_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192787 entries, 0 to 199999\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   fare_amount        192787 non-null  float64\n",
      " 1   pickup_longitude   192787 non-null  float64\n",
      " 2   pickup_latitude    192787 non-null  float64\n",
      " 3   dropoff_longitude  192787 non-null  float64\n",
      " 4   dropoff_latitude   192787 non-null  float64\n",
      " 5   passenger_count    192787 non-null  int64  \n",
      " 6   year               192787 non-null  int32  \n",
      " 7   weekday            192787 non-null  int32  \n",
      " 8   Monthly_Quarter    192787 non-null  int64  \n",
      " 9   Hourly_Segments    192787 non-null  int64  \n",
      " 10  distance_traveled  192787 non-null  float64\n",
      "dtypes: float64(6), int32(2), int64(3)\n",
      "memory usage: 16.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference: The dataset doesn't have any duplicates\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "rows,columns = df.shape\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop(['pickup_latitude','pickup_longitude',\n",
    "         'dropoff_latitude','dropoff_longitude'],axis=1)\n",
    "if df.shape==(rows,columns):\n",
    "    print('Inference: The dataset doesn\\'t have any duplicates')\n",
    "else:\n",
    "    print(f'Inference: Number of duplicates dropped fixed ---> {rows-df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  ['passenger_count', 'year',\n",
    "             'weekday', 'Monthly_Quarter', \n",
    "             'Hourly_Segments', 'distance_traveled']\n",
    "\n",
    "target = 'fare_amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into X and Y\n",
    "X, y = df[features], df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "\n",
      "passenger_count\n",
      "year\n",
      "weekday\n",
      "Monthly_Quarter\n",
      "Hourly_Segments\n",
      "distance_traveled\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(score_func=f_regression, k=6)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "\n",
    "print(\"Selected features:\\n\")\n",
    "print('\\n'.join(map(str, selected_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Train and test set, Data Scaling and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual splitting up to 2015 data\n",
    "train, test = df[df.year < 2015], df[df.year == 2015]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (179407, 6)\n",
      "y_train shape: (179407,)\n",
      "X_test shape: (13380, 6)\n",
      "y_test shape: (13380,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179407, 6), (179407,), (13380, 6), (13380,))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_collection = {\n",
    "    'Random_Forest_1': RandomForestRegressor(),\n",
    "    'Decision_tree_1': DecisionTreeRegressor(),\n",
    "    'Linear_Regression_1': LinearRegression(),\n",
    "    'XGBoost_1': XGBRegressor(),\n",
    "    'Lasso_1': Lasso(),\n",
    "    'Gradient_Boost_1' : GradientBoostingRegressor(),\n",
    "    'High_Gradient_Boost_1' : HistGradientBoostingRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models: 100%|██████████| 7/7 [01:23<00:00, 11.97s/it]\n"
     ]
    }
   ],
   "source": [
    "train_test_results = {}\n",
    "\n",
    "for model_name, model in tqdm(models_collection.items(), desc='Training Models'):\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    trained_data_mae, trained_data_mse, trained_data_r2 = eval_model(y_train, y_train_pred)\n",
    "    test_data_mae, test_data_mse, test_data_r2 = eval_model(y_test, y_test_pred)\n",
    "\n",
    "    train_test_results[model_name] = {\n",
    "        'Train': {\n",
    "            'Train_MAE': trained_data_mae,\n",
    "            'Train_R2': trained_data_r2,\n",
    "            'Train_mse': trained_data_mse\n",
    "        },\n",
    "        'Test': {\n",
    "            'Test_MAE': test_data_mae,\n",
    "            'Test_R2': test_data_r2,\n",
    "            'Test_mse': test_data_mse\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Model                     Train_MSE Test_MSE Train_R2 Test_R2 \n",
      "-----------------------------------------------------------------\n",
      "Random_Forest_1           2.353     17.872    0.973     0.855    \n",
      "Decision_tree_1           0.062     42.260    0.999     0.656    \n",
      "Linear_Regression_1       86.265    122.500   0.018     0.003    \n",
      "XGBoost_1                 11.418    15.400    0.870     0.875    \n",
      "Lasso_1                   87.542    124.973   0.004     -0.017   \n",
      "Gradient_Boost_1          14.090    14.740    0.840     0.880    \n",
      "High_Gradient_Boost_1     15.251    15.734    0.826     0.872    \n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*65)\n",
    "print('{:<25s} {:<8s} {:<8s} {:<8s} {:<8s}'.format('Model', 'Train_MSE', 'Test_MSE', 'Train_R2', 'Test_R2'))\n",
    "print('-'*65)\n",
    "for model_name, model_results in train_test_results.items():\n",
    "    print('{:<25s} {:<9.3f} {:<9.3f} {:<9.3f} {:<9.3f}'.format(\n",
    "        model_name,\n",
    "        model_results['Train']['Train_mse'],\n",
    "        model_results['Test']['Test_mse'],\n",
    "        model_results['Train']['Train_R2'],\n",
    "        model_results['Test']['Test_R2'],\n",
    "    ))\n",
    "print('-'*65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-Fold Cross Validation, Data Scaling and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_1 = StandardScaler()\n",
    "# taking all features to x fold and y fold as target data\n",
    "X_fold = scalar_1.fit_transform(df[features])\n",
    "y_fold = df.fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kfold_models = {\n",
    "    'Random_Forest_2': RandomForestRegressor(),\n",
    "    'Decision_tree_2': DecisionTreeRegressor(),\n",
    "    'Linear_Regression_2': LinearRegression(),\n",
    "    'XGBoost_2': XGBRegressor(),\n",
    "    'Lasso_2': Lasso(),\n",
    "    'Gradient_Boost_2' : GradientBoostingRegressor(),\n",
    "    'High_Gradient_Boost_2' : HistGradientBoostingRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models: 100%|██████████| 7/7 [05:32<00:00, 47.53s/it] \n"
     ]
    }
   ],
   "source": [
    "kfold_results = {}\n",
    "\n",
    "folds = 5\n",
    "k_folds = KFold(n_splits=folds)\n",
    "\n",
    "for model_name, model in tqdm(Kfold_models.items(), desc='Training Models'):\n",
    "    scores = cross_val_score(model, X_fold, y_fold.ravel(), scoring='r2')\n",
    "    \n",
    "    kfold_results[model_name] = {\n",
    "        'Fold_Scores': scores,\n",
    "        'Average_Score': np.mean(scores),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Model                     R2 Scores                           Average R2  \n",
      "----------------------------------------------------------------------\n",
      "Random_Forest_2           0.810, 0.827, 0.824, 0.805, 0.819   0.817       \n",
      "Decision_tree_2           0.639, 0.654, 0.639, 0.649, 0.629   0.642       \n",
      "Linear_Regression_2       0.018, 0.018, 0.019, 0.018, 0.021   0.019       \n",
      "XGBoost_2                 0.826, 0.846, 0.842, 0.821, 0.841   0.835       \n",
      "Lasso_2                   0.004, 0.004, 0.004, 0.005, 0.004   0.004       \n",
      "Gradient_Boost_2          0.825, 0.848, 0.844, 0.825, 0.841   0.837       \n",
      "High_Gradient_Boost_2     0.809, 0.835, 0.826, 0.819, 0.829   0.823       \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*70)\n",
    "print('{:<25s} {:<35s} {:<12s}'.format('Model', 'R2 Scores', 'Average R2'))\n",
    "print('-'*70)\n",
    "for model_name, model_results in kfold_results.items():\n",
    "    scores_str = ', '.join([f'{score:.3f}' for score in model_results['Fold_Scores']])\n",
    "    print('{:<25s} {:<35s} {:<12.3f}'.format(model_name, scores_str, model_results['Average_Score']))\n",
    "print('-'*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameter\n",
    "Using Optuna for tuning\n",
    "- tuning Hyper parameters of Xgboost cause <b>XGBOOST IS ALL YOU NEED</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "def save_object(obj):\n",
    "    \"\"\"\n",
    "        saving the object in a specific path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"artifacts\", 'model.pkl')\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            pickle.dump(obj, file_obj)\n",
    "        logging.info(f\"Object Saved at : {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 0.5, 30),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "    }\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Hyperparameter:  32%|███▏      | 64/200 [54:20<1:55:28, 50.95s/it]\n",
      "[I 2023-08-19 22:25:22,080] A new study created in memory with name: no-name-50e80982-d85f-42da-9914-35382d0f0384\n",
      "[I 2023-08-19 22:25:30,826] Trial 0 finished with value: 0.8822786004618786 and parameters: {'max_depth': 73, 'subsample': 0.6212236894732276, 'colsample_bytree': 0.7229419886245455, 'colsample_bylevel': 0.4150445217909544, 'min_child_weight': 23, 'reg_lambda': 0.11212666725968802, 'reg_alpha': 0.10056299129821245, 'n_estimators': 206, 'learning_rate': 0.09944578176656922}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   1%|          | 2/200 [00:08<14:25,  4.37s/it][I 2023-08-19 22:29:47,215] Trial 1 finished with value: 0.813766930676756 and parameters: {'max_depth': 447, 'subsample': 0.8230052928729708, 'colsample_bytree': 0.9750900777841958, 'colsample_bylevel': 0.8502591373755145, 'min_child_weight': 11, 'reg_lambda': 0.0514006698247006, 'reg_alpha': 0.47108118599931625, 'n_estimators': 764, 'learning_rate': 0.09718199177607205}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   2%|▏         | 3/200 [04:25<5:59:08, 109.38s/it][I 2023-08-19 22:30:12,209] Trial 2 finished with value: 0.8501594806769759 and parameters: {'max_depth': 235, 'subsample': 0.5668230491473302, 'colsample_bytree': 0.1313061235438206, 'colsample_bylevel': 0.021387220564575864, 'min_child_weight': 10, 'reg_lambda': 0.015675611876015627, 'reg_alpha': 0.6827766224628968, 'n_estimators': 609, 'learning_rate': 0.032005797215573076}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   2%|▏         | 4/200 [04:50<4:14:26, 77.89s/it] [I 2023-08-19 22:32:05,483] Trial 3 finished with value: 0.8731102652816376 and parameters: {'max_depth': 237, 'subsample': 0.28668734798899254, 'colsample_bytree': 0.8632533744727637, 'colsample_bylevel': 0.6194783580033817, 'min_child_weight': 14, 'reg_lambda': 0.11410524132456795, 'reg_alpha': 0.6125404357387091, 'n_estimators': 839, 'learning_rate': 0.02205816507089816}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   2%|▎         | 5/200 [06:43<4:53:08, 90.20s/it][I 2023-08-19 22:32:50,966] Trial 4 finished with value: 0.8596433393780222 and parameters: {'max_depth': 484, 'subsample': 0.304346034376791, 'colsample_bytree': 0.27699702197122594, 'colsample_bylevel': 0.18505170990575587, 'min_child_weight': 17, 'reg_lambda': 0.11879325891634508, 'reg_alpha': 0.09368152921919493, 'n_estimators': 876, 'learning_rate': 0.09062032244986461}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   3%|▎         | 6/200 [07:28<4:03:39, 75.36s/it][I 2023-08-19 22:33:21,687] Trial 5 finished with value: 0.8729065442537657 and parameters: {'max_depth': 297, 'subsample': 0.3437433576836487, 'colsample_bytree': 0.9685194187643781, 'colsample_bylevel': 0.7112875404771472, 'min_child_weight': 23, 'reg_lambda': 0.01615309373890122, 'reg_alpha': 0.5409787613548951, 'n_estimators': 226, 'learning_rate': 0.08087956076261185}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   4%|▎         | 7/200 [07:59<3:16:13, 61.00s/it][I 2023-08-19 22:33:40,998] Trial 6 finished with value: 0.8789409420920944 and parameters: {'max_depth': 330, 'subsample': 0.6627081491451069, 'colsample_bytree': 0.5015184037612587, 'colsample_bylevel': 0.578307076165299, 'min_child_weight': 1, 'reg_lambda': 0.15798884527788584, 'reg_alpha': 0.12786080414560647, 'n_estimators': 531, 'learning_rate': 0.09149116907235484}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   4%|▍         | 8/200 [08:18<2:33:12, 47.88s/it][I 2023-08-19 22:33:53,964] Trial 7 finished with value: 0.8439071579468204 and parameters: {'max_depth': 222, 'subsample': 0.13955342467948312, 'colsample_bytree': 0.25056605246323543, 'colsample_bylevel': 0.9840006835942484, 'min_child_weight': 30, 'reg_lambda': 0.7841694501452093, 'reg_alpha': 0.28763409884436186, 'n_estimators': 496, 'learning_rate': 0.03888904074380994}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   4%|▍         | 9/200 [08:31<1:57:55, 37.05s/it][I 2023-08-19 22:34:23,417] Trial 8 finished with value: 0.8590324654684938 and parameters: {'max_depth': 176, 'subsample': 0.5506398768142959, 'colsample_bytree': 0.057778607058875706, 'colsample_bylevel': 0.4816305276223473, 'min_child_weight': 19, 'reg_lambda': 0.8832588759853093, 'reg_alpha': 0.39175091754119185, 'n_estimators': 718, 'learning_rate': 0.035194080712126645}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   5%|▌         | 10/200 [09:01<1:49:55, 34.71s/it][I 2023-08-19 22:34:30,336] Trial 9 finished with value: 0.8769698025350922 and parameters: {'max_depth': 492, 'subsample': 0.664556710875811, 'colsample_bytree': 0.8389160039677438, 'colsample_bylevel': 0.03815631523440426, 'min_child_weight': 7, 'reg_lambda': 0.03859688525402874, 'reg_alpha': 0.0460058335924987, 'n_estimators': 150, 'learning_rate': 0.04715516694186928}. Best is trial 0 with value: 0.8822786004618786.\n",
      "Optimizing Hyperparameter:   6%|▌         | 11/200 [09:08<1:22:39, 26.24s/it][I 2023-08-19 22:34:41,876] Trial 10 finished with value: 0.8839435880016349 and parameters: {'max_depth': 15, 'subsample': 0.9820223251735295, 'colsample_bytree': 0.6577776804112193, 'colsample_bylevel': 0.3730159247165207, 'min_child_weight': 27, 'reg_lambda': 0.3085422914127324, 'reg_alpha': 0.01885241257146007, 'n_estimators': 353, 'learning_rate': 0.06592696838183282}. Best is trial 10 with value: 0.8839435880016349.\n",
      "Optimizing Hyperparameter:   6%|▌         | 12/200 [09:19<1:08:14, 21.78s/it][I 2023-08-19 22:34:52,380] Trial 11 finished with value: 0.884025339090211 and parameters: {'max_depth': 9, 'subsample': 0.979031027375924, 'colsample_bytree': 0.5957449042177575, 'colsample_bylevel': 0.38915763979649065, 'min_child_weight': 28, 'reg_lambda': 0.2898671382693855, 'reg_alpha': 0.010100570499274705, 'n_estimators': 350, 'learning_rate': 0.06611448945835084}. Best is trial 11 with value: 0.884025339090211.\n",
      "Optimizing Hyperparameter:   6%|▋         | 13/200 [09:30<57:15, 18.37s/it]  [I 2023-08-19 22:35:04,771] Trial 12 finished with value: 0.8841381045558406 and parameters: {'max_depth': 19, 'subsample': 0.9990207065749652, 'colsample_bytree': 0.615519567557383, 'colsample_bylevel': 0.34043544611639415, 'min_child_weight': 30, 'reg_lambda': 0.346090955930323, 'reg_alpha': 0.010026720687597537, 'n_estimators': 375, 'learning_rate': 0.06665090495055505}. Best is trial 12 with value: 0.8841381045558406.\n",
      "Optimizing Hyperparameter:   7%|▋         | 14/200 [09:42<51:21, 16.57s/it][I 2023-08-19 22:35:17,260] Trial 13 finished with value: 0.8842971190250754 and parameters: {'max_depth': 79, 'subsample': 0.9988759458401157, 'colsample_bytree': 0.5150240221707038, 'colsample_bylevel': 0.3173849520781472, 'min_child_weight': 30, 'reg_lambda': 0.33145963431806796, 'reg_alpha': 0.012083452334129626, 'n_estimators': 369, 'learning_rate': 0.0626100914064938}. Best is trial 13 with value: 0.8842971190250754.\n",
      "Optimizing Hyperparameter:   8%|▊         | 15/200 [09:55<47:17, 15.34s/it][I 2023-08-19 22:35:28,376] Trial 14 finished with value: 0.8824511155648024 and parameters: {'max_depth': 107, 'subsample': 0.8580534888326402, 'colsample_bytree': 0.4826513646115583, 'colsample_bylevel': 0.2661902713767663, 'min_child_weight': 24, 'reg_lambda': 0.40950403066501845, 'reg_alpha': 0.010941433799783993, 'n_estimators': 386, 'learning_rate': 0.057163888724576596}. Best is trial 13 with value: 0.8842971190250754.\n",
      "Optimizing Hyperparameter:   8%|▊         | 16/200 [10:06<43:08, 14.07s/it][I 2023-08-19 22:35:41,259] Trial 15 finished with value: 0.8843803733335283 and parameters: {'max_depth': 119, 'subsample': 0.8504757725040977, 'colsample_bytree': 0.3994322791320287, 'colsample_bylevel': 0.2484139957339615, 'min_child_weight': 30, 'reg_lambda': 0.5242043476509812, 'reg_alpha': 0.023041279763691205, 'n_estimators': 436, 'learning_rate': 0.07480298379150288}. Best is trial 15 with value: 0.8843803733335283.\n",
      "Optimizing Hyperparameter:   8%|▊         | 17/200 [10:19<41:49, 13.71s/it][I 2023-08-19 22:35:59,236] Trial 16 finished with value: 0.8839329496967444 and parameters: {'max_depth': 136, 'subsample': 0.8042076190353569, 'colsample_bytree': 0.38607283528435943, 'colsample_bylevel': 0.23988279962640063, 'min_child_weight': 21, 'reg_lambda': 0.5624706989221, 'reg_alpha': 0.024605562292654124, 'n_estimators': 624, 'learning_rate': 0.07765870994473326}. Best is trial 15 with value: 0.8843803733335283.\n",
      "Optimizing Hyperparameter:   9%|▉         | 18/200 [10:37<45:28, 14.99s/it][I 2023-08-19 22:36:13,114] Trial 17 finished with value: 0.8830956423951092 and parameters: {'max_depth': 79, 'subsample': 0.873343480086723, 'colsample_bytree': 0.4163821821692411, 'colsample_bylevel': 0.15443427385586658, 'min_child_weight': 26, 'reg_lambda': 0.2229568138192958, 'reg_alpha': 0.02629147198967917, 'n_estimators': 465, 'learning_rate': 0.053556209477637104}. Best is trial 15 with value: 0.8843803733335283.\n",
      "Optimizing Hyperparameter:  10%|▉         | 19/200 [10:51<44:13, 14.66s/it][I 2023-08-19 22:36:21,266] Trial 18 finished with value: 0.8788490292717002 and parameters: {'max_depth': 168, 'subsample': 0.7496774897898626, 'colsample_bytree': 0.3397434989636318, 'colsample_bylevel': 0.3001170390142428, 'min_child_weight': 2, 'reg_lambda': 0.6124755067976588, 'reg_alpha': 0.04589271452011435, 'n_estimators': 274, 'learning_rate': 0.07885577122029115}. Best is trial 15 with value: 0.8843803733335283.\n",
      "Optimizing Hyperparameter:  10%|█         | 20/200 [10:59<38:06, 12.71s/it][I 2023-08-19 22:36:25,610] Trial 19 finished with value: 0.5551161939591724 and parameters: {'max_depth': 368, 'subsample': 0.9148511005667961, 'colsample_bytree': 0.5376134255726863, 'colsample_bylevel': 0.48418819439560484, 'min_child_weight': 19, 'reg_lambda': 0.9634900042999455, 'reg_alpha': 0.017371604347923137, 'n_estimators': 136, 'learning_rate': 0.015136171715682406}. Best is trial 15 with value: 0.8843803733335283.\n",
      "Optimizing Hyperparameter:  10%|█         | 21/200 [11:03<30:25, 10.20s/it][I 2023-08-19 22:36:43,810] Trial 20 finished with value: 0.8840775310995594 and parameters: {'max_depth': 70, 'subsample': 0.7489014280926338, 'colsample_bytree': 0.44698980782687253, 'colsample_bylevel': 0.14099084761318198, 'min_child_weight': 26, 'reg_lambda': 0.4994030221593889, 'reg_alpha': 0.03787461251300599, 'n_estimators': 625, 'learning_rate': 0.07241257541933542}. Best is trial 15 with value: 0.8843803733335283.\n",
      "Optimizing Hyperparameter:  11%|█         | 22/200 [11:21<37:22, 12.60s/it][I 2023-08-19 22:36:57,863] Trial 21 finished with value: 0.8844037238206924 and parameters: {'max_depth': 28, 'subsample': 0.9876627789200387, 'colsample_bytree': 0.6124969036895713, 'colsample_bylevel': 0.3163011819850793, 'min_child_weight': 30, 'reg_lambda': 0.3745045098698959, 'reg_alpha': 0.013480655495063398, 'n_estimators': 431, 'learning_rate': 0.061917206542594354}. Best is trial 21 with value: 0.8844037238206924.\n",
      "Optimizing Hyperparameter:  12%|█▏        | 23/200 [11:35<38:27, 13.03s/it][I 2023-08-19 22:37:13,677] Trial 22 finished with value: 0.8846096051165879 and parameters: {'max_depth': 141, 'subsample': 0.9175033260614776, 'colsample_bytree': 0.5405986359915991, 'colsample_bylevel': 0.2800563269216088, 'min_child_weight': 30, 'reg_lambda': 0.22567821347428085, 'reg_alpha': 0.015629937101445425, 'n_estimators': 469, 'learning_rate': 0.05819168174327932}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  12%|█▏        | 24/200 [11:51<40:40, 13.87s/it][I 2023-08-19 22:37:51,705] Trial 23 finished with value: 0.8803643555730896 and parameters: {'max_depth': 170, 'subsample': 0.9088922468950831, 'colsample_bytree': 0.6870511884340301, 'colsample_bylevel': 0.2192242573126085, 'min_child_weight': 27, 'reg_lambda': 0.20204243071383382, 'reg_alpha': 0.016988690829882937, 'n_estimators': 966, 'learning_rate': 0.053520243096451814}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  12%|█▎        | 25/200 [12:29<1:01:35, 21.12s/it][I 2023-08-19 22:38:07,394] Trial 24 finished with value: 0.8833620613449875 and parameters: {'max_depth': 127, 'subsample': 0.783475525866809, 'colsample_bytree': 0.5561707784008968, 'colsample_bylevel': 0.11048395670139671, 'min_child_weight': 24, 'reg_lambda': 0.48152169650317966, 'reg_alpha': 0.02865094195322304, 'n_estimators': 452, 'learning_rate': 0.0455890301474879}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  13%|█▎        | 26/200 [12:45<56:31, 19.49s/it]  [I 2023-08-19 22:38:23,507] Trial 25 finished with value: 0.8839668472788157 and parameters: {'max_depth': 42, 'subsample': 0.906285921530169, 'colsample_bytree': 0.4122872634947299, 'colsample_bylevel': 0.26697550642279916, 'min_child_weight': 30, 'reg_lambda': 0.2102482991744648, 'reg_alpha': 0.015540158775825924, 'n_estimators': 572, 'learning_rate': 0.06007139578389687}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  14%|█▎        | 27/200 [13:01<53:16, 18.48s/it][I 2023-08-19 22:38:32,722] Trial 26 finished with value: 0.8821781604068555 and parameters: {'max_depth': 124, 'subsample': 0.9219990714543156, 'colsample_bytree': 0.5997031882252409, 'colsample_bylevel': 0.42268199751652324, 'min_child_weight': 21, 'reg_lambda': 0.5676921444245943, 'reg_alpha': 0.021748189983481717, 'n_estimators': 277, 'learning_rate': 0.0723027600820201}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  14%|█▍        | 28/200 [13:10<44:59, 15.70s/it][I 2023-08-19 22:38:50,014] Trial 27 finished with value: 0.8827523598502635 and parameters: {'max_depth': 200, 'subsample': 0.8434123077292601, 'colsample_bytree': 0.7284019350224737, 'colsample_bylevel': 0.20940374448031301, 'min_child_weight': 27, 'reg_lambda': 0.25036602543294895, 'reg_alpha': 0.014501130501187407, 'n_estimators': 422, 'learning_rate': 0.056012200470136476}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  14%|█▍        | 29/200 [13:27<46:06, 16.18s/it][I 2023-08-19 22:39:09,864] Trial 28 finished with value: 0.8838239440119319 and parameters: {'max_depth': 48, 'subsample': 0.7223734234849983, 'colsample_bytree': 0.4749570270926482, 'colsample_bylevel': 0.09739309322529233, 'min_child_weight': 25, 'reg_lambda': 0.38005669484000015, 'reg_alpha': 0.03370163433413591, 'n_estimators': 675, 'learning_rate': 0.048927074239102926}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  15%|█▌        | 30/200 [13:47<48:57, 17.28s/it][I 2023-08-19 22:39:30,627] Trial 29 finished with value: 0.8823304671682057 and parameters: {'max_depth': 280, 'subsample': 0.8034125327511028, 'colsample_bytree': 0.7154382299527767, 'colsample_bylevel': 0.320109328807632, 'min_child_weight': 21, 'reg_lambda': 0.6448692662989118, 'reg_alpha': 0.013891645605673691, 'n_estimators': 529, 'learning_rate': 0.06010989415412242}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  16%|█▌        | 31/200 [14:08<51:36, 18.32s/it][I 2023-08-19 22:39:41,227] Trial 30 finished with value: 0.8828989023074264 and parameters: {'max_depth': 107, 'subsample': 0.8542093925829792, 'colsample_bytree': 0.576366501476963, 'colsample_bylevel': 0.4163367123309297, 'min_child_weight': 29, 'reg_lambda': 0.15027157465135432, 'reg_alpha': 0.02143349416360812, 'n_estimators': 314, 'learning_rate': 0.0712315075294945}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  16%|█▌        | 32/200 [14:19<44:49, 16.01s/it][I 2023-08-19 22:39:55,657] Trial 31 finished with value: 0.8838586060473748 and parameters: {'max_depth': 74, 'subsample': 0.9559314719886408, 'colsample_bytree': 0.549423712184884, 'colsample_bylevel': 0.322936205865252, 'min_child_weight': 28, 'reg_lambda': 0.37260473044758696, 'reg_alpha': 0.011981792558317828, 'n_estimators': 429, 'learning_rate': 0.06040002361223485}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  16%|█▋        | 33/200 [14:33<43:14, 15.53s/it][I 2023-08-19 22:40:11,597] Trial 32 finished with value: 0.8840178999796213 and parameters: {'max_depth': 90, 'subsample': 0.9487616248518396, 'colsample_bytree': 0.5252449899771916, 'colsample_bylevel': 0.2590495132236311, 'min_child_weight': 30, 'reg_lambda': 0.28085287133983494, 'reg_alpha': 0.014078392132567036, 'n_estimators': 486, 'learning_rate': 0.06360542204922039}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  17%|█▋        | 34/200 [14:49<43:18, 15.66s/it][I 2023-08-19 22:40:18,545] Trial 33 finished with value: 0.8659900744953678 and parameters: {'max_depth': 48, 'subsample': 0.9997238910819942, 'colsample_bytree': 0.3597602938961202, 'colsample_bylevel': 0.35885069700285444, 'min_child_weight': 28, 'reg_lambda': 0.4177872530934995, 'reg_alpha': 0.018701632343223817, 'n_estimators': 251, 'learning_rate': 0.05350420335455662}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  18%|█▊        | 35/200 [14:56<35:52, 13.04s/it][I 2023-08-19 22:40:34,804] Trial 34 finished with value: 0.8836799585620688 and parameters: {'max_depth': 146, 'subsample': 0.8759267251470281, 'colsample_bytree': 0.4769077553813631, 'colsample_bylevel': 0.19948324319083666, 'min_child_weight': 25, 'reg_lambda': 0.7329182732327885, 'reg_alpha': 0.013619957740214378, 'n_estimators': 571, 'learning_rate': 0.07007465779460026}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  18%|█▊        | 36/200 [15:12<38:17, 14.01s/it][I 2023-08-19 22:40:48,523] Trial 35 finished with value: 0.881944702209904 and parameters: {'max_depth': 56, 'subsample': 0.9273126372254704, 'colsample_bytree': 0.6504363595148577, 'colsample_bylevel': 0.27531001894461293, 'min_child_weight': 13, 'reg_lambda': 0.3112390829876482, 'reg_alpha': 0.02117109114522489, 'n_estimators': 404, 'learning_rate': 0.08368950304043044}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  18%|█▊        | 37/200 [15:26<37:49, 13.92s/it][I 2023-08-19 22:40:57,788] Trial 36 finished with value: 0.8821285861487197 and parameters: {'max_depth': 208, 'subsample': 0.8276898523778542, 'colsample_bytree': 0.44082690563619636, 'colsample_bylevel': 0.4436857853550939, 'min_child_weight': 23, 'reg_lambda': 0.08488000056724171, 'reg_alpha': 0.012064504437079338, 'n_estimators': 321, 'learning_rate': 0.0741143286166847}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  19%|█▉        | 38/200 [15:35<33:48, 12.52s/it][I 2023-08-19 22:41:22,634] Trial 37 finished with value: 0.8597140642924519 and parameters: {'max_depth': 98, 'subsample': 0.9365153458549608, 'colsample_bytree': 0.3178715007046291, 'colsample_bylevel': 0.33080268926181905, 'min_child_weight': 29, 'reg_lambda': 0.4578848610219571, 'reg_alpha': 0.030103799703049612, 'n_estimators': 526, 'learning_rate': 0.0839011095260649}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  20%|█▉        | 39/200 [16:00<43:31, 16.22s/it][I 2023-08-19 22:41:29,935] Trial 38 finished with value: 0.8139367349951879 and parameters: {'max_depth': 253, 'subsample': 0.8841329888168039, 'colsample_bytree': 0.26331733506130595, 'colsample_bylevel': 0.5474861042396479, 'min_child_weight': 9, 'reg_lambda': 0.17642495886592852, 'reg_alpha': 0.01589375396963008, 'n_estimators': 203, 'learning_rate': 0.06442968305455736}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  20%|██        | 40/200 [16:07<36:07, 13.55s/it][I 2023-08-19 22:41:56,615] Trial 39 finished with value: 0.8824175286191835 and parameters: {'max_depth': 420, 'subsample': 0.9978285682627076, 'colsample_bytree': 0.514061863355743, 'colsample_bylevel': 0.1741381553494833, 'min_child_weight': 26, 'reg_lambda': 0.24152189884504968, 'reg_alpha': 0.010005714790252373, 'n_estimators': 803, 'learning_rate': 0.06892029243054267}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  20%|██        | 41/200 [16:34<46:20, 17.49s/it][I 2023-08-19 22:42:14,866] Trial 40 finished with value: 0.8832972336826191 and parameters: {'max_depth': 149, 'subsample': 0.9461404384340388, 'colsample_bytree': 0.39459670804684005, 'colsample_bylevel': 0.3723470178589826, 'min_child_weight': 23, 'reg_lambda': 0.7509553445226302, 'reg_alpha': 0.024996290527766037, 'n_estimators': 668, 'learning_rate': 0.075065883630369}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  21%|██        | 42/200 [16:52<46:38, 17.72s/it][I 2023-08-19 22:42:27,261] Trial 41 finished with value: 0.8841226980752163 and parameters: {'max_depth': 12, 'subsample': 0.9888403150532307, 'colsample_bytree': 0.6184507217789279, 'colsample_bylevel': 0.2931791991465369, 'min_child_weight': 30, 'reg_lambda': 0.33985786474988294, 'reg_alpha': 0.011192145580264856, 'n_estimators': 375, 'learning_rate': 0.0662776767075124}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  22%|██▏       | 43/200 [17:05<42:10, 16.12s/it][I 2023-08-19 22:42:43,538] Trial 42 finished with value: 0.8845037152726313 and parameters: {'max_depth': 30, 'subsample': 0.9523495747451489, 'colsample_bytree': 0.6284458820504314, 'colsample_bylevel': 0.32676638386894663, 'min_child_weight': 30, 'reg_lambda': 0.36977700103236255, 'reg_alpha': 0.013145280537787433, 'n_estimators': 480, 'learning_rate': 0.06222971607170018}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  22%|██▏       | 44/200 [17:21<42:01, 16.17s/it][I 2023-08-19 22:43:00,200] Trial 43 finished with value: 0.8842484209599669 and parameters: {'max_depth': 37, 'subsample': 0.888847886414089, 'colsample_bytree': 0.5200128610565453, 'colsample_bylevel': 0.22006581270630485, 'min_child_weight': 28, 'reg_lambda': 0.49767177643124694, 'reg_alpha': 0.019017315113500913, 'n_estimators': 495, 'learning_rate': 0.06048592556836194}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  22%|██▎       | 45/200 [17:38<42:08, 16.31s/it][I 2023-08-19 22:43:17,622] Trial 44 finished with value: 0.8823082142288979 and parameters: {'max_depth': 65, 'subsample': 0.9577839151950412, 'colsample_bytree': 0.7624500644136939, 'colsample_bylevel': 0.4524206058863725, 'min_child_weight': 29, 'reg_lambda': 0.2783843647563432, 'reg_alpha': 0.013165592462230374, 'n_estimators': 446, 'learning_rate': 0.0631960944038766}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  23%|██▎       | 46/200 [17:55<42:43, 16.65s/it][I 2023-08-19 22:43:28,658] Trial 45 finished with value: 0.8818149648451715 and parameters: {'max_depth': 112, 'subsample': 0.8454382691692939, 'colsample_bytree': 0.6602284761667815, 'colsample_bylevel': 0.38494773115853204, 'min_child_weight': 16, 'reg_lambda': 0.38512582952562896, 'reg_alpha': 0.017053609739484325, 'n_estimators': 313, 'learning_rate': 0.050312384838622666}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  24%|██▎       | 47/200 [18:06<38:09, 14.96s/it][I 2023-08-19 22:43:48,256] Trial 46 finished with value: 0.8833845032842929 and parameters: {'max_depth': 86, 'subsample': 0.47675066152989515, 'colsample_bytree': 0.5956646771369362, 'colsample_bylevel': 0.5200402318303052, 'min_child_weight': 6, 'reg_lambda': 0.6846239791509365, 'reg_alpha': 0.02381421578549128, 'n_estimators': 550, 'learning_rate': 0.05773989374278734}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  24%|██▍       | 48/200 [18:26<41:25, 16.35s/it][I 2023-08-19 22:43:53,314] Trial 47 finished with value: 0.8009021544368844 and parameters: {'max_depth': 38, 'subsample': 0.9530229358303806, 'colsample_bytree': 0.21554587055346539, 'colsample_bylevel': 0.3435272162000652, 'min_child_weight': 28, 'reg_lambda': 0.8358126760675626, 'reg_alpha': 0.012498383256809626, 'n_estimators': 180, 'learning_rate': 0.0677221388885352}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  24%|██▍       | 49/200 [18:31<32:37, 12.97s/it][I 2023-08-19 22:44:05,141] Trial 48 finished with value: 0.8809170022827892 and parameters: {'max_depth': 190, 'subsample': 0.8941084203390298, 'colsample_bytree': 0.5612744175693744, 'colsample_bylevel': 0.25749620950330454, 'min_child_weight': 30, 'reg_lambda': 0.30640074987498345, 'reg_alpha': 0.020380245826867118, 'n_estimators': 355, 'learning_rate': 0.041974832251491456}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  25%|██▌       | 50/200 [18:43<31:33, 12.62s/it][I 2023-08-19 22:44:17,313] Trial 49 finished with value: 0.8824095420377083 and parameters: {'max_depth': 8, 'subsample': 0.9659060667089167, 'colsample_bytree': 0.45432355411554987, 'colsample_bylevel': 0.40767928029124273, 'min_child_weight': 25, 'reg_lambda': 0.5503665343557075, 'reg_alpha': 0.07214917196304041, 'n_estimators': 481, 'learning_rate': 0.05070201978744868}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  26%|██▌       | 51/200 [18:55<31:00, 12.49s/it][I 2023-08-19 22:44:29,111] Trial 50 finished with value: 0.8828100280616373 and parameters: {'max_depth': 150, 'subsample': 0.8152777985070085, 'colsample_bytree': 0.497312102159589, 'colsample_bylevel': 0.31220330900207993, 'min_child_weight': 27, 'reg_lambda': 0.259318159289015, 'reg_alpha': 0.01603631476500559, 'n_estimators': 405, 'learning_rate': 0.056531377623245935}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  26%|██▌       | 52/200 [19:07<30:17, 12.28s/it][I 2023-08-19 22:44:46,367] Trial 51 finished with value: 0.8842905563199108 and parameters: {'max_depth': 28, 'subsample': 0.876952644282991, 'colsample_bytree': 0.5202014953377357, 'colsample_bylevel': 0.23640834905401445, 'min_child_weight': 29, 'reg_lambda': 0.4427457029838988, 'reg_alpha': 0.01007930253371568, 'n_estimators': 503, 'learning_rate': 0.06205931120843345}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  26%|██▋       | 53/200 [19:24<33:44, 13.77s/it][I 2023-08-19 22:45:03,780] Trial 52 finished with value: 0.8840494606897648 and parameters: {'max_depth': 28, 'subsample': 0.9122705148698862, 'colsample_bytree': 0.6239374808188668, 'colsample_bylevel': 0.23609420734114436, 'min_child_weight': 29, 'reg_lambda': 0.4414192178879745, 'reg_alpha': 0.010543372727202587, 'n_estimators': 517, 'learning_rate': 0.06364935036752375}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  27%|██▋       | 54/200 [19:41<36:10, 14.87s/it][I 2023-08-19 22:45:23,900] Trial 53 finished with value: 0.8840786283260043 and parameters: {'max_depth': 61, 'subsample': 0.8652483761329172, 'colsample_bytree': 0.5699607350190213, 'colsample_bylevel': 0.16931258350484357, 'min_child_weight': 30, 'reg_lambda': 0.3419927762414875, 'reg_alpha': 0.01236968116164329, 'n_estimators': 598, 'learning_rate': 0.06930363980088988}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  28%|██▊       | 55/200 [20:01<39:44, 16.44s/it][I 2023-08-19 22:45:38,893] Trial 54 finished with value: 0.8842656295058899 and parameters: {'max_depth': 28, 'subsample': 0.9728074919618102, 'colsample_bytree': 0.5022309299091887, 'colsample_bylevel': 0.29136628476940135, 'min_child_weight': 27, 'reg_lambda': 0.5940471306665424, 'reg_alpha': 0.010077023168822315, 'n_estimators': 429, 'learning_rate': 0.06208898487785699}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  28%|██▊       | 56/200 [20:16<38:25, 16.01s/it][I 2023-08-19 22:45:48,822] Trial 55 finished with value: 0.8829861681148916 and parameters: {'max_depth': 6, 'subsample': 0.9273567033672389, 'colsample_bytree': 0.4297518085940178, 'colsample_bylevel': 0.3620103338655748, 'min_child_weight': 29, 'reg_lambda': 0.44666872476626024, 'reg_alpha': 0.014597545245282015, 'n_estimators': 459, 'learning_rate': 0.057499330625094144}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  28%|██▊       | 57/200 [20:26<33:48, 14.18s/it][I 2023-08-19 22:46:02,341] Trial 56 finished with value: 0.8828327513865397 and parameters: {'max_depth': 86, 'subsample': 0.7782817775483718, 'colsample_bytree': 0.5385826567235525, 'colsample_bylevel': 0.2351870877212351, 'min_child_weight': 26, 'reg_lambda': 0.92105926474457, 'reg_alpha': 0.017932179532794128, 'n_estimators': 384, 'learning_rate': 0.06671404465288633}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  29%|██▉       | 58/200 [20:40<33:05, 13.98s/it][I 2023-08-19 22:46:17,845] Trial 57 finished with value: 0.8830127689065204 and parameters: {'max_depth': 69, 'subsample': 0.9999577372902564, 'colsample_bytree': 0.4515707445504511, 'colsample_bylevel': 0.18802932489485488, 'min_child_weight': 18, 'reg_lambda': 0.20726920285907532, 'reg_alpha': 0.012008178570128113, 'n_estimators': 563, 'learning_rate': 0.07565020014308438}. Best is trial 22 with value: 0.8846096051165879.\n",
      "Optimizing Hyperparameter:  30%|██▉       | 59/200 [20:55<33:56, 14.44s/it][W 2023-08-19 22:46:26,582] Trial 58 failed with parameters: {'max_depth': 120, 'subsample': 0.8980380577418864, 'colsample_bytree': 0.3792609706653196, 'colsample_bylevel': 0.1305227683598833, 'min_child_weight': 24, 'reg_lambda': 0.34839718832784017, 'reg_alpha': 0.027193954889516068, 'n_estimators': 333, 'learning_rate': 0.054361723343341925} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/4z/164gfgdx59g5sq2cjmrfqlhc0000gn/T/ipykernel_86878/4087416469.py\", line 14, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2023-08-19 22:46:26,589] Trial 58 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[callback])\n\u001b[1;32m     10\u001b[0m progress_bar\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     12\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[190], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m500\u001b[39m),\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m),\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m XGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 14\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mscore(X_test, y_test\u001b[39m.\u001b[39mravel())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ZenMLCustom/lib/python3.9/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(total=200, desc='Optimizing Hyperparameter', dynamic_ncols=True)\n",
    "\n",
    "def callback(study, trial):\n",
    "    progress_bar.n = len(study.trials)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200, callbacks=[callback])\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "\n",
    "model = XGBRegressor(**best_params)\n",
    "\n",
    "save_object(obj=model)\n",
    "\n",
    "print(\"Best Hyperparameter for XGBRegressor:\")\n",
    "print(best_params)\n",
    "print(\"Best R2 Score: {:.3f}\".format(best_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
